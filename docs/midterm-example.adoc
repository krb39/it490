= Midterm Example
:sourceroot: ..
:sourcedir: example-midterm

image::all.png[align=center, width=25%]

== Introduction

This section summarizes the content so far and provides an example of a system
that implements basic the midterm milestones. This example is just one way to
build a system . It's not the only way, in fact it's not even the best way.
Your system will likely be quite different to meet the individual needs of your
project. The example's purpose is to show you a solution that avoids common
pitfalls. Hopefully you can integrate some of the lessons of this example into
your project. 

The project is structured in such a way that *Front End* and *Back End* never
communicate directly and *Back End* is the only service that can write to the
*Database*:

[plantuml, "overview_compose", svg]
....
@startuml

actor Users

node frontend [
    Front End
]

node backend [
    Back End
]

node Messaging

database Database

Users <-> frontend
frontend <-> Messaging
Messaging <-> backend
backend <-> Database

@enduml
....

This allows for more scalability when we introduce replication in the second
half of the semester.

The entire example can be found in the `{sourcedir}` directory which has the
following directory structure:

----
│   .env
│   docker-compose.yml
│
├───back_end
│       app.py
│       Dockerfile
│       requirements.txt
│
├───db
│       Dockerfile
│       setup.sql
│
└───front_end
    │   app.py
    │   Dockerfile
    │   requirements.txt
    │   wait-for-it.sh
    │
    └───templates
            base.html
            login.html
            register.html
----

TIP: Notice the `.env` file in the directory structure. docker-compose will
load environment variables from this file that you can then use in the
`docker-compose.yml` file. This keeps you from having to repeat yourself when
multiple services need the same information. For example, both *Database* and
*Back End* need to know the `POSTGRES_PASSWORD`. It also allows you to have a
single secret file that you can put in `.gitignore` to keep out of your
repository.

== Messaging

In our example, the *Messaging* can be run straight from the
https://hub.docker.com/_/rabbitmq[RabbitMQ Docker Hub image] via the
`docker-compose.yml` file, hence the absence of a `messaging` directory with a
`Dockerfile` in the directory structure. The image allows for sufficient
configuration via its environment variables. At this point it is recommended
that you still run the management interface and forward the management interface
port, 15672, so that you can see how the queues are being used. The messaging
service will be used in the
https://www.rabbitmq.com/tutorials/tutorial-six-python.html[request / reply pattern]
detailed in the diagram below:

[plantuml, "messaging", svg]
....
@startuml

node frontend [
    Front End
]

node backend [
    Back End
]

node Messaging {
    queue requests [
        Requests Queue
    ]
    queue replies [
        Reply Queues
        ----
        Client 1
        ....
        Client 2
        ....
        . . .
    ]
}

frontend --> requests : AMQP
frontend <-- replies : AMQP
backend <-- requests : AMQP
backend --> replies : AMQP

@enduml
....

Fortunately this works out-of-the-box since queue creation is handled by the
by the clients. The service simply has to be up and running to function.

The service definition in `docker-compose.yml` can be seen here:

.{sourcedir}/docker-compose.yml (excerpted)
[source, yml]
----
include::{sourceroot}/{sourcedir}/docker-compose.yml[tags=messaging]
----

== Database

*Database* is responsible for storing the persistent information the system
uses. It only communicates with *Back End*.

[plantuml, database, svg]
....
@startuml

node backend [
    Back End
]

database db [
    Database
    ----
    USERS
    ....
    . . .
]

backend <-> db

@enduml
....

In this example, *Database* creates a database and the appropriate tables _if_
the database is currently empty. This can be done by placing the SQL file that
we want executed in `/docker-entrypoint-initdb.d/` of the image. Our
`{sourcedir}/db/Dockerfile` handles copying our initialization SQL
appropriately:

.{sourcedir}/db/Dockerfile
[source, docker]
----
include::{sourceroot}/{sourcedir}/db/Dockerfile[]
----

.{sourcedir}/db/setup.sql
[source, sql]
----
include::{sourceroot}/{sourcedir}/db/setup.sql[]
----

The schema in this example is quite simple, consisting of a database and a
single table for holding emails and hashes. It should be noted that the `\c`
command is specific to PostgreSQL and it is the equivalent of a `USE` statement
in MySQL, meaning _use_ that particular database.

The relevant service definition in the `docker-compose.yml` file can be seen
here:

.{sourcedir}/docker-compose.yml (excerpted)
[source, yml]
----
include::{sourceroot}/{sourcedir}/docker-compose.yml[tags=db]
----

The database files are stored in a Docker volume named `data-volume` and the
password for our database is loaded from an environment variable defined in
`.env`.

TIP: The https://hub.docker.com/_/adminer/[adminer] image is a great way to see
what's going on in your database. It provides a web interface to many different
types of databases that can be easily accessed via port 8080. See the example
`docker-compose.yml` file for an example of its use.

== Back End

*Back End* brokers the exchange of information between *Messaging* and
*Database*. It also provides an area to perform the tasks needed to support the
complete system such as web scraping or computation. At this point, our example
does not include any of the latter and mainly focuses on storing / utilizing
authentication information in the database.

You can think of *Back End* as providing an API that is accessible through
*Messaging*. Any language can be a good choice for the *Back End* as long as it
has libraries to interface with *Database* and *Messaging*.

.Popular Libraries used by *Back End*
Python::
* https://www.psycopg.org/[psycopg2] (PostgreSQL)
* https://dev.mysql.com/doc/connector-python/en/[mysql.connector] (MySQL / MariaDB)
* https://github.com/pika/pika[pika] (RabbitMQ)
PHP::
* https://www.php.net/manual/en/book.mysqli.php[mysqli] (MySQL / MariaDB)
* https://github.com/php-amqplib/php-amqplib[php-amqplib] (RabbitMQ)
JavaScript::
* https://node-postgres.com/[node-postgres] (PostgreSQL)
* https://mariadb.com/kb/en/getting-started-with-the-nodejs-connector/[mariadb] (MySQL / MariaDB)
* http://www.squaremobius.net/amqp.node/[amqplib] (RabbitMQ)

[plantuml, "backend", svg]
....
@startuml

node "Back End" {
    rectangle dblib [
        mysql.connector / psycopg2 / mysqli
    ]
    rectangle messaginglib [
        pika / php-amqplib
    ]
}

node Messaging
database Database

messaginglib <--> Messaging : AMQP
dblib <-> Database : DB proto over TCP

@enduml
....

The code for the *Back End* example is entirely contained in
`{sourcedir}/back_end/app.py`. *Back End* starts by connecting to both
*Messaging* and *Database* using the pika and psycopg2 libraries respectively.
With Docker Compose you don't know when the services will become available so
the example repeatedly attempts to connect, waiting up to 60 seconds and
https://en.wikipedia.org/wiki/Exponential_backoff[backing off exponentially]
each time. Below is an example of typical startup output:

[source, console]
----
PS example-midterm> docker-compose logs --tail=100 back_end | Select-String -Pattern root

back_end_1   | INFO:root:Waiting 1s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Waiting 2s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Waiting 4s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Waiting 8s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Starting consumption...
----

The example then creates the required database cursor, messaging channel,
messaging queues, and sets up a callback for messages arriving in the `requests`
queue. This is where the majority of work is performed and the function can be
seen here:

.{sourcedir}/back_end/app.py (excerpted)
[source, python]
----
include::{sourceroot}/{sourcedir}/back_end/app.py[tags=process_request]
----

WARNING: Notice that psycopg2 functions are used to put variables into the SQL
statements. Do *NOT* use Python string formating to build your SQL statements.
You may be thinking that we are in *Back End* and the parameters we receive are
already https://xkcd.com/327/[sanitized] by *Front End* but this is not always
the case.

== Front End

*Front End* can be created using any web framework, but the most popular choices
are https://www.php.net[PHP] or https://palletsprojects.com/p/flask[Flask]. The
most popular Docker Hub images for those frameworks are
link:++https://hub.docker.com/_/php++[php:apache] and
https://hub.docker.com/_/python[python] respectively. For interacting with
*Messaging* there are a few options, but groups tend to gravitate towards
https://github.com/php-amqplib/php-amqplib[php-amqplib] for PHP and
https://github.com/pika/pika[pika] for Python Flask. This is probably due to
the fact that the
https://www.rabbitmq.com/getstarted.html[documentation for RabbitMQ] references
those libraries.

[plantuml, frontend, svg]
....
@startuml

actor Users

node "Front End" {
    rectangle messaginglib [
        php-amqplib / pika
    ]
    rectangle webframework [
        php / Flask
    ]
}

node Messaging 

Users --> webframework : HTTP
messaginglib <-> Messaging : AMQP 

@enduml
....

A custom `{sourcedir}/front_end/Dockerfile` is used for creating the image:

.{sourcedir}/front_end/Dockerfile
[source, docker]
----
include::{sourceroot}/{sourcedir}/front_end/Dockerfile[]
----

A script called https://github.com/vishnubob/wait-for-it[`wait-for-it.sh`] is
included with the image. It is used
https://docs.docker.com/compose/startup-order/[as recommended by the Docker documentation]
to make sure *Messaging* is up before *Front End* starts. This way *Front End*
will not give errors to users who attempt to use it before the full system has
started.

`{sourcedir}/front_end/Dockerfile` is built in the service section of the
`{sourcedir}/docker-compose.yml` file:

.{sourcedir}/docker-compose.yml (excerpted)
[source, yml]
----
include::{sourceroot}/{sourcedir}/docker-compose.yml[tags=front_end]
----

There are a few things in this service definition that should be noted:

* Port `5000` needs to be forwarded as it will be accessed externally
* The `FLASK_ENV` environment variable is useful for development. It causes
  Flask to print more friendly error messages right inside the web browser.
* `front_end/` is bind mounted to `/app` in the container even though the
  `Dockerfile` copies those files to the `/app` directory when the image is
  created. This allows for easier development, the container can be running
  while you edit the files Flask is using. The development server will
  automatically restart if changes are detected.

To make communication with *Messaging* easier,
`{sourcedir}/front_end/messaging.py` defines a `Messaging` class that
initializes the connection, shuts down the connection, and provides a send and
receive function. All messages are sent to the general `requests` queue and
replies are returned via an exclusive reply queue.

.{sourcedir}/front_end/messaging.py
[source, python]
----
include::{sourceroot}/{sourcedir}/front_end/messaging.py[]
----

WARNING: Every HTTP request received by *Front End* will result in a full
connection sequence with *Messaging* which is not optimal. A 
https://github.com/eandersson/python-rabbitmq-examples/blob/master/Flask-examples/pika_async_rpc_example.py[better solution]
is to have the `Messaging` class run in its own thread and maintain a permanent
connection.

Let's take a look at a registration sequence involving the *User*, *Front End*,
and *Back End*:

[plantuml, registration, svg]
....
@startuml

User -> "Front End": HTTP GET /register
"Front End" --> User: register.html
User -> "Front End": HTTP POST /register email password
"Front End" -> Messaging: REGISTER email hash
Messaging --> "Front End": SUCCESS or FAILURE
"Front End" --> User: redirect OR error

@enduml
....

The relevant code in `{sourcedir}/front_end/app.py` follows:

.{sourcedir}/front_end/app.py (excerpted)
[source, python]
----
include::{sourceroot}/{sourcedir}/front_end/app.py[tags=register]
----

Fortunately password hashing functions are readily available in the
`werkzeug.security` module. https://palletsprojects.com/p/werkzeug/[Werkzeug]
is a WSGI utility library that Flask already uses, so we don't need to add
anything to `requirements.txt`. We can use the functions `check_password_hash`
and `generate_password_hash`.

WARNING: Do *NOT* store user passwords in cleartext. There are plenty of good
hashing options in both PHP and Python. Try to minimize systems that come in
contact with unencrypted passwords as well. In this example it is hashed before
it is even passed to the *Back End*. For the same reason, in production your
users should only be able to connect via TLS (HTTPS). This will secure the
channel between *User* and *Front End* which passes the password when the user
registers or logs in.

The `register` function will also set `email` in the user session upon
successful completion. This is akin to having a user log in automatically once
they have created an account.
https://flask.palletsprojects.com/en/1.1.x/api/#flask.session[Flask sessions]
are a good way of storing things on the client that can't be modified. They
default to a lifetime of 31 days.

A similar sequence is used to log in a user:

[plantuml, login, svg]
....
@startuml

User -> "Front End": HTTP GET /login
"Front End" --> User: login.html
User -> "Front End": HTTP POST /login email password
"Front End" -> Messaging: GETHASH email
Messaging --> "Front End": hash OR error
"Front End" --> User: redirect OR error

@enduml
....

The relevant code in `{sourcedir}/front_end/app.py` follows:

.{sourcedir}/front_end/app.py (excerpted)
[source, python]
----
include::{sourceroot}/{sourcedir}/front_end/app.py[tags=login]
----

Compared to the `register` function, handling a login is simpler. A few other
routes of interest with brief descriptions are:

[horizontal]
`/`:: serves `index.html`
`/logout`:: removes `email` from the user's session and redirects to `/`
`/secret`:: protected by the `@login_required` decorator (see below), serves
`secret.html`

https://realpython.com/primer-on-python-decorators/[Python decorators] are used
for routing in Flask so it is a natural fit to use them to protect routes as
well. The `@login_required` decorator does exactly that:

.{sourcedir}/front_end/app.py (excerpted)
[source, python]
----
include::{sourceroot}/{sourcedir}/front_end/app.py[tags=login_required]
----

== Questions

[qanda]
What is the advantage of using a `.env` file and referencing it from docker-compose.yml?::
    A `.env` file allows you to have a single source of information for things
    that may be used by multiple services. This way you only have to make a
    change in one file if you want to make an adjustment. This helps prevent
    errors due to forgetting to change a variable in multiple places. It also
    allows you to store your secrets in one file that you can then keep out of
    your public repository.
Why do we store password _hashes_ instead of just the passwords?::
    Hashes are more secure because they are a one-way function. You can convert
    a password to its hash, but you _cannot_ convert a hash to its password. As
    such, if your system is compromised an attacker would not get the passwords
    of your users.
Why is port `5000` the only port that needs to be forwarded to the local host?::
    All other communication in this system takes place inside the Docker
    network that Docker Compose builds. The only interface a user needs to this
    system is through port 5000 on *Front End*.
What does the `adminer` image do?::
    Adminer provides a web-based interface to your database. This can be very
    useful for looking at the data in your database and making sure everything
    is working the way you expect it to.
What role does *Messaging* play in this system?::
    Messaging brokers the communication between *Front End* and *Back End*. By
    using a *Messaging* layer, we make our system more scalable. In the future
    we may wish to run multiple *Front Ends* or *Back Ends*. With a *Messaging*
    layer that transition should be simple.
